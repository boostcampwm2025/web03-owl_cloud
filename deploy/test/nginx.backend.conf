# 동시에 처리 가능한 프로세스 수 설정 
worker_processes auto;

# 하나의 process는 1024개의 동시 연결이다.
events {
  worker_connections 1024;
}

http {

  upstream main_backend_app {
    # load balancer 
    least_conn;

    # backend 헬스 체크 추가
    keepalive 64;

    # 10초 동안 3번의 연결실패가 일어나면 그 앱은 닫는다. 
    # kubernetes라면 이를 관리해주는 요소가 있어서 나중에는 변경할 예정이다.
    server main-backend-app-1:8080 max_fails=3 fail_timeout=10s;
    server main-backend-app-2:8080 max_fails=3 fail_timeout=10s;
    server main-backend-app-3:8080 max_fails=3 fail_timeout=10s;
  }

  server {
    listen 80;
    server_name _;

    # http 1.1을 사용하는데 2는 고려 중이다. -> 현재로서는 일단 1.1 사용해야할 것 같다.
    location / {
      proxy_pass         http://main_backend_app;
      proxy_http_version 1.1;
      
      # keepalive도 고려하였음 
      proxy_set_header Connection "";
      proxy_set_header   Host $host;
      proxy_set_header   X-Real-IP $remote_addr;
      proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header   X-Forwarded-Proto $scheme;

      # 아래는 나중에 카드 업로드가 생겼을때 옮겨주면 된다.

      # 큰 영상 업로드에 경우 따로 처리해주어야 한다. -> 우리 서비스에서는 필요
      # 어디 크기까지 허용할지 정하는 것이다. -> 이 크기를 초과 하면 backend 서버까지 가지 않고 nginx에서 cut 한다. -> backend는 예외처리 안해도 되니까 편안 
      # 서버에 따라서 다르게 처리할 수 있다. 일단은 msa를 적용하지 않았기 때문에 이렇게만 처리
      client_max_body_size 500m;

      # proxy 연결을 기다리는 요소
      # 위부터 연결까지 3초 보내는데 읽는데 각각 30s만 기다린다.
      # 우리나라에 경우 500mb에 20mbps라는 가정하에 5분이 안걸리기는 하지만 10m정도로 잡아도 좋을듯 싶다.
      proxy_connect_timeout 5s;
      proxy_send_timeout 10m;
      proxy_read_timeout 10m;

      # time이 만약 넘어가면 다른 app으로 전달한다. 
      # 네트워크에러, 시간 초과, 502, 503, 504 에러가 발생하면 2번까지 다시 연결을 시도한다. -> load balancer를 사용할때 안정성을 위해서 설계
      proxy_next_upstream error timeout http_502 http_503 http_504;
      proxy_next_upstream_tries 2;
    }
  }

}