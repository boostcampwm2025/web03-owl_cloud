# 동시에 처리 가능한 프로세스 수 설정 
worker_processes auto;

# 하나의 process는 4096개의 동시 연결이다.
events {
  worker_connections 4096;
}

http {

  upstream tool_backend_app {
    # load balancer 
    least_conn;

    keepalive 64;

    # 10초 동안 3번의 연결실패가 일어나면 그 앱은 닫는다. 
    # kubernetes라면 이를 관리해주는 요소가 있어서 나중에는 변경할 예정이다.
    server tool-backend-app-1:8000 max_fails=3 fail_timeout=10s;
    server tool-backend-app-2:8000 max_fails=3 fail_timeout=10s;
    server tool-backend-app-3:8000 max_fails=3 fail_timeout=10s;
  }

  # websocket용 upstream 추가 
  # 지금 당장은 websocket이 여러군데 가도 괜찮다. ( redis adapter 덕분 )
  upstream tool_backend_ws {
    # sfu 서버로 사용하게 되어서 주석 처리 ( 나중에 websocket은 이걸 사용할 수 있다. )
    # # load_balancer 떄문에 바뀌지 않도록 이를 수정해준다. ( room_id를 기반으로 앱을 매핑 )
    # # consistent를 이용해서 서버가 늘거나 삭제되도 대부분은 그대로 서버를 유지하도록 한다. 
    hash $arg_room_code consistent; 

    server tool-backend-app-1:8000 max_fails=3 fail_timeout=10s;
    server tool-backend-app-2:8000 max_fails=3 fail_timeout=10s;
    server tool-backend-app-3:8000 max_fails=3 fail_timeout=10s;
  }

  server {
    listen 80;
    server_name _;

    location ^~ /tool/ws {
      # room_id가 없으면 에러를 발생시켜야 한다.
      # nginx는 $arg_<파라미터이름>으로 매핑을 시킨다. 
      if ($arg_room_code = "") { return 400; }

      proxy_pass http://tool_backend_ws;

      # 전역적으로 설정했지만 안전성을 위해서 한번 더
      proxy_http_version 1.1;

      # 웹소켓 업그레이드 
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection "upgrade";

      proxy_set_header Host              $host;
      proxy_set_header X-Real-IP         $remote_addr;
      proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
      proxy_set_header X-Forwarded-Host $host;

      # 연결 높이기 
      proxy_read_timeout 3600s;
      proxy_send_timeout 3600s;

      # 실시간 성을 위해서 추가
      proxy_buffering off;

      # 다음 websocket으로 이동하지 못하게 한다. 
      proxy_next_upstream off;
      
      # 인메모리 설정을 사용하면서 아래는 다시 막게되었다. 
      # 결국 websocket도 현재 서버가 중요하지 않기 때문에 만약 해당 websocket이 불량이라면 여기서 에러가 있는것은 넘긴다. 
      # 연결은 최대 5초까지 가능
      # proxy_connect_timeout 5s; 
      # proxy_next_upstream error timeout http_502 http_503 http_504;
      # proxy_next_upstream_tries 2;
    }

    # sse를 사용하는 경우 버퍼링을 꺼주고 오래 연결이 가능하도록 해주어야 한다. -> 지금은 사용하지 않지만 마지막에 sse가 있으면 이를 이용하도록 할 예정이다.
    location ^~ /tool/sse/ {
      proxy_pass http://tool_backend_app;

      proxy_http_version 1.1;
      proxy_set_header Connection "";

      proxy_set_header Host              $host;
      proxy_set_header X-Real-IP         $remote_addr;
      proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;

      # buffering 꺼주기 -> 실시간으로 바로 보낼 수 있도록 하기 위함이다. 
      proxy_buffering off;
      proxy_cache off;
      add_header X-Accel-Buffering no always;


      # 오랫동안 연결되도록 하기 1시간
      proxy_read_timeout 3600s;
      proxy_send_timeout 3600s;

      # 응답을 메모리/디스크에 쌓지 않고 바로 전달하도록 한다. 
      proxy_request_buffering off;

      # 스트리밍에 경우 업스트림을 교체하지 않는다. 
      proxy_next_upstream off;

      # sse가 캐시되지 않도록 명시
      add_header Cache-Control "no-cache" always;

      proxy_set_header Accept-Encoding "";
      gzip off;
    }

    # 메트릭이 일단 /tool/metrics에서는 수집할 수 없게 해야 한다.
    location = /tool/metrics  { return 404; }
    location = /tool/metrics/ { return 404; }

    # metric 수집은 infra 서버에서만 가능하도록 설정 (app1, app2, app3) -> 
    location = /tool/metrics/app1 {
      proxy_pass http://tool-backend-app-1:8000/tool/metrics;

      proxy_http_version 1.1;
      proxy_set_header Host              $host;
      proxy_set_header X-Real-IP         $remote_addr;
      proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
    }

    location = /tool/metrics/app2 {
      proxy_pass http://tool-backend-app-2:8000/tool/metrics;

      proxy_http_version 1.1;
      proxy_set_header Host              $host;
      proxy_set_header X-Real-IP         $remote_addr;
      proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
    }

    location = /tool/metrics/app3 {
      proxy_pass http://tool-backend-app-3:8000/tool/metrics;

      proxy_http_version 1.1;
      proxy_set_header Host              $host;
      proxy_set_header X-Real-IP         $remote_addr;
      proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
    }

    # http 1.1을 사용하는데 2는 고려 중이다. -> 현재로서는 일단 1.1 사용해야할 것 같다.
    location ^~ /tool/  {
      proxy_pass http://tool_backend_app;
      proxy_http_version 1.1;
      
      # keepalive도 고려하였음 
      proxy_set_header Connection "";
      proxy_set_header   Host $host;
      proxy_set_header   X-Real-IP $remote_addr;
      proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header   X-Forwarded-Proto $scheme;

      # 아래는 나중에 카드 업로드가 생겼을때 옮겨주면 된다.

      # 큰 영상 업로드에 경우 따로 처리해주어야 한다. -> 우리 서비스에서는 필요
      # 어디 크기까지 허용할지 정하는 것이다. -> 이 크기를 초과 하면 backend 서버까지 가지 않고 nginx에서 cut 한다. -> backend는 예외처리 안해도 되니까 편안 
      # 서버에 따라서 다르게 처리할 수 있다. 일단은 msa를 적용하지 않았기 때문에 이렇게만 처리
      client_max_body_size 10m;

      # proxy 연결을 기다리는 요소
      # 위부터 연결까지 3초 보내는데 읽는데 각각 30s만 기다린다.
      # 우리나라에 경우 500mb에 20mbps라는 가정하에 5분이 안걸리기는 하지만 10m정도로 잡아도 좋을듯 싶다. -> s3로 파일을 보내기 때문에 이제 적게 잡아도 괜찮다.
      proxy_connect_timeout 5s;
      proxy_send_timeout 1m;
      proxy_read_timeout 1m;

      # time이 만약 넘어가면 다른 app으로 전달한다. 
      # 네트워크에러, 시간 초과, 502, 503, 504 에러가 발생하면 2번까지 다시 연결을 시도한다. -> load balancer를 사용할때 안정성을 위해서 설계
      proxy_next_upstream error timeout http_502 http_503 http_504;
      proxy_next_upstream_tries 2;
    }

    
    # 디버깅을 위한 추가
    location / {
      return 404;
    }
  }

}